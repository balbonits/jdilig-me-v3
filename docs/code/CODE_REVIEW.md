# CODE_REVIEW - Guide for Reviewing AI-Generated Code

## Purpose
This guide helps you systematically review code generated by Claude Code and changes to the site, ensuring quality, maintainability, and alignment with project conventions.

## 🔍 Quick Checklist

### Before AI Makes Changes
- [ ] Is the task clearly defined and scoped?
- [ ] Have you specified what NOT to do?
- [ ] Is the AI using TodoWrite to track progress?

### After AI Makes Changes
- [ ] Run `npm run lint` - Any new errors?
- [ ] Run `npm run build` - Does it build successfully?
- [ ] Run `npm test:run` - Do all tests pass?
- [ ] Check git diff - Are changes minimal and focused?

## 📋 Detailed Review Areas

### 1. Code Conventions
```bash
# Check for semicolons (should be everywhere)
grep -r "[^;]$" src/ --include="*.tsx" --include="*.ts" | grep -v "//"

# Check for proper type imports
grep -r "import {.*ReactNode" src/ # Should be: import type { ReactNode }
```

**Review Points:**
- ✅ All statements end with semicolons
- ✅ Type-only imports use `import type`
- ✅ Components use named exports (not default)
- ✅ Props use `interface` not `type`
- ✅ Files follow naming conventions

### 2. Component Structure
```
components/[category]/[ComponentName]/
├── ComponentName.tsx        # Check: Named export matches folder?
├── ComponentName.test.tsx   # Check: Tests exist and run?
├── ComponentName.stories.ts # Check: Stories work in Storybook?
└── index.ts                # Check: Barrel export present?
```

**Review Points:**
- ✅ Component in correct category folder
- ✅ All related files co-located
- ✅ No business logic in UI components
- ✅ Props are well-typed with TypeScript

### 3. File Changes Scope

**Red Flags - Too Much Changed:**
- 🚩 More than 5 files modified for simple feature
- 🚩 New folders/structures without discussion
- 🚩 New dependencies added without approval
- 🚩 Config files modified unexpectedly
- 🚩 Documentation created proactively

**Good Signs - Appropriate Scope:**
- ✅ Only requested files modified
- ✅ Changes focused on single concern
- ✅ No "while I'm here" improvements
- ✅ Follows existing patterns

### 4. Performance & Bundle Size
```bash
# Check bundle size before/after
npm run build
# Look at: dist/assets/index-*.js size

# Check for unnecessary imports
grep -r "import \* as" src/  # Usually bad
```

**Review Points:**
- ✅ No importing entire libraries
- ✅ Images referenced from `/public/` not imported
- ✅ Large dependencies justified
- ✅ Lazy loading used for routes

### 5. Security
```bash
# Check for dangerous patterns
grep -r "dangerouslySetInnerHTML" src/
grep -r "eval(" src/
grep -r "innerHTML" src/
grep -r "window.location.href =" src/  # Should use router
```

**Review Points:**
- ✅ No inline scripts or styles
- ✅ No direct DOM manipulation
- ✅ User input sanitized
- ✅ No hardcoded secrets/keys

### 6. Accessibility
```bash
# Check for basic a11y
grep -r "<img" src/ | grep -v "alt="  # Images need alt text
grep -r "<button" src/ | grep -v "type="  # Buttons need type
```

**Review Points:**
- ✅ Semantic HTML used
- ✅ ARIA labels where needed
- ✅ Keyboard navigation works
- ✅ Focus states visible

## 🧪 Testing Checklist

### Unit Tests
```bash
npm run test:run
```
- [ ] All tests pass
- [ ] New components have tests
- [ ] Coverage hasn't decreased significantly

### Build Test
```bash
npm run build
npm run preview  # Test production build locally
```
- [ ] Build completes without errors
- [ ] Site works in preview mode
- [ ] No console errors in browser

### Manual Testing
- [ ] Click through all routes
- [ ] Test on mobile viewport
- [ ] Check dark/light mode (if implemented)
- [ ] Test offline mode (PWA)

## 🎯 Common AI Mistakes to Watch For

1. **Over-engineering**
   - Creating abstractions too early
   - Adding features not requested
   - Making "helpful" improvements

2. **Inconsistent Patterns**
   - Not following existing code style
   - Using different approach than rest of codebase
   - Mixing paradigms (class/functional)

3. **Missing Context**
   - Not reading existing code first
   - Duplicating functionality
   - Breaking existing features

4. **File Management**
   - Creating files in wrong location
   - Not using folder structure correctly
   - Forgetting barrel exports

## 📝 Review Commands

```bash
# Full review sequence
npm run lint          # Check code quality
npm run build         # Ensure it builds
npm run test:run      # Run tests
npm run storybook     # Check component stories

# Git review
git status            # What changed?
git diff              # Review changes
git diff --stat       # How much changed?

# Find issues
npx tsc --noEmit      # TypeScript errors?
grep -r "TODO" src/   # Any TODOs left?
grep -r "console.log" src/  # Debug logs removed?
```

## 🚀 Deployment Review

Before deploying to Vercel:
- [ ] `npm run build:ssg` works (if using SSG)
- [ ] No sensitive data in code
- [ ] Environment variables documented
- [ ] PWA manifest updated if needed
- [ ] Performance acceptable (< 3s load time)

## 💡 Quick Wins

If AI-generated code has issues, ask it to:
1. "Fix ESLint errors without disabling rules"
2. "Add missing semicolons"
3. "Convert to use existing patterns from [file]"
4. "Reduce this to minimal implementation"
5. "Add tests for this component"

## ⚠️ When to Reject Changes

Reject and request redo if:
- Build is broken
- Tests fail
- Multiple unrelated changes mixed together
- Conventions ignored
- Too much code for simple feature
- Security issues introduced
- Performance significantly degraded

## 📊 Metrics to Track

- **Lines changed**: Prefer smaller, focused changes
- **Test coverage**: Should maintain or improve
- **Bundle size**: Monitor for unexpected growth
- **Build time**: Should stay under 30 seconds
- **Lighthouse score**: Maintain 90+ for performance

---

Remember: The goal is maintainable, human-readable code that you can understand and modify yourself. If you can't understand what the AI did, request simpler implementation.